#![allow(unused)]

// rule function {
//   'fn' ident <commit> '(' fn_args ')' '->' type expr
// }

pub mod grammar;

use ariadne::{sources, Color, Label, Report, ReportKind};
use chumsky::prelude::*;
use std::{collections::HashMap, env, fmt, fs};

pub type Span = SimpleSpan<usize>;

#[derive(Clone, Debug, PartialEq)]
enum Token<'src> {
    Str(&'src str),
    Ident(&'src str),
    // parens
    LParen,
    RParen,
    LBrace,
    RBrace,
    Pipe,
    // keywords
    Rule,
    Function,
}

impl<'src> fmt::Display for Token<'src> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            Token::Str(a) => write!(f, "'{a}'"),
            Token::Ident(a) => a.fmt(f),
            Token::LParen => '('.fmt(f),
            Token::RParen => ')'.fmt(f),
            Token::LBrace => '{'.fmt(f),
            Token::RBrace => '}'.fmt(f),
            Token::Pipe => '|'.fmt(f),
            Token::Rule => "rule".fmt(f),
            Token::Function => "function".fmt(f),
        }
    }
}

fn lexer<'src>(
) -> impl Parser<'src, &'src str, Vec<(Token<'src>, Span)>, extra::Err<Rich<'src, char, Span>>> {
    // A parser for strings
    let str = just('\'')
        .ignore_then(none_of('\'').repeated())
        .then_ignore(just('\''))
        .map_slice(Token::Str);

    let ctrl = one_of("(){}|").map(|c| match c {
        '(' => Token::LParen,
        ')' => Token::RParen,
        '{' => Token::LBrace,
        '}' => Token::RBrace,
        '|' => Token::Pipe,
        _ => unreachable!(),
    });

    // A parser for identifiers and keywords
    let ident = text::ident().map(|ident: &str| match ident {
        "rule" => Token::Rule,
        "function" => Token::Function,
        _ => Token::Ident(ident),
    });

    // A single token can be one of the above
    let token = ident.or(str).or(ctrl);

    let comment = just("//")
        .then(any().and_is(just('\n').not()).repeated())
        .padded();

    token
        .map_with_span(|tok, span| (tok, span))
        .padded_by(comment.repeated())
        .padded()
        // If we encounter an error, skip and attempt to lex the next character as a token instead
        .recover_with(skip_then_retry_until(any().ignored(), end()))
        .repeated()
        .collect()
}

pub type Spanned<T> = (T, Span);

// An expression node in the AST. Children are spanned so we can generate useful runtime errors.
#[derive(Debug)]
enum Expr<'src> {
    Terminal(&'src str),
    NonTerminal(&'src str),
    // structuring node
    Sequence(Vec<Expr<'src>>),
    // postfix repetition
    OneOrMore(Box<Expr<'src>>),
    ZeroOrMore(Box<Expr<'src>>),
    Maybe(Box<Expr<'src>>),
    Choice(Box<Expr<'src>>, Box<Expr<'src>>),
    // immediatelly matches, just an empty rule
    Empty,
    Error,
}

// A function node in the AST.
#[derive(Debug)]
struct Rule<'src> {
    args: Vec<&'src str>,
    body: Expr<'src>,
    function_span: Span,
    body_span: Span,
}

// The type of the input that our parser operates on. The input is the `&[(Token, Span)]` token buffer generated by the
// lexer, wrapped in a `SpannedInput` which 'splits' it apart into its constituent parts, tokens and spans, for chumsky
// to understand.
type ParserInput<'tokens, 'src> =
    chumsky::input::SpannedInput<Token<'src>, Span, &'tokens [(Token<'src>, Span)]>;

// This looks complex, but don't be scared!

// There are two lifetimes here:
//     - 'src: the lifetime of the underlying source code (the string we read from disk)
//     - 'tokens: the lifetime of the token buffer emitted by the lexer
// Our source code lives longer than the token buffer, hence `'src: 'tokens`

// From this function, we return a parser that parses an input of type `ParserInput` (see above for an explanation of
// that) and produces a `Spanned<Expr>` (an expression with a span attached to it, so we can point to the right thing
// for runtime errors).

// We also specify an error type used by the parser. In this case, it's `Rich`, one of chumsky's default error types.
fn expr_parser<'tokens, 'src: 'tokens>() -> impl Parser<
    'tokens,
    ParserInput<'tokens, 'src>,
    Spanned<Expr<'src>>,
    extra::Err<Rich<'tokens, Token<'src>, Span>>,
> + Clone {
    recursive(|expr| {
        let symbol = select! {
            Token::Str(a) => Expr::Terminal(a),
            Token::Ident(a) => Expr::NonTerminal(a),
        }
        .or(expr);

        // 'srctoms' are expressions that contain no ambiguity
        let atom = symbol
            // .map_with_span(|expr, span| (expr, span))
            // Atoms can also just be normal expressions, but surrounded with parentheses
            .or(expr
                .clone()
                .delimited_by(just(Token::LParen), just(Token::RParen)))
            // Attempt to recover anything that looks like a parenthesised expression but contains errors
            // .recover_with(via_parser(nested_delimiters(
            //     Token::LParen,
            //     Token::RParen,
            //     [(Token::LBrace, Token::RBrace)],
            //     |span| (Expr::Error, span),
            // )))
            .boxed();

        let mono = atom.then(choice);

        // A list of expressions
        let sequence = atom
            .clone()
            .repeated()
            .collect::<Vec<_>>()
            .map(Expr::Sequence);

        sequence.then(just(Token::Pipe)).or_not()
    })
}

fn funcs_parser<'tokens, 'src: 'tokens>() -> impl Parser<
    'tokens,
    ParserInput<'tokens, 'src>,
    HashMap<&'src str, Func<'src>>,
    extra::Err<Rich<'tokens, Token<'src>, Span>>,
> + Clone {
    let ident = select! { Token::Ident(ident) => ident.clone() };

    // Argument lists are just identifiers separated by commas, surrounded by parentheses
    let args = ident
        .separated_by(just(Token::Ctrl(',')))
        .allow_trailing()
        .collect()
        .delimited_by(just(Token::LParen), just(Token::RParen))
        .labelled("function args");

    let func = just(Token::Fn)
        .ignore_then(
            ident
                .map_with_span(|name, span| (name, span))
                .labelled("function name"),
        )
        .then(args)
        .map_with_span(|start, span| (start, span))
        .then(
            expr_parser()
                .delimited_by(just(Token::LBrace), just(Token::RBrace))
                // Attempt to recover anything that looks like a function body but contains errors
                .recover_with(via_parser(nested_delimiters(
                    Token::LBrace,
                    Token::RBrace,
                    [
                        (Token::LParen, Token::RParen),
                        (Token::Ctrl('['), Token::Ctrl(']')),
                    ],
                    |span| (Expr::Error, span),
                ))),
        )
        .map(|(((name, args), span), body)| (name, Func { args, span, body }))
        .labelled("function");

    func.repeated()
        .collect::<Vec<_>>()
        .validate(|fs, _, emitter| {
            let mut funcs = HashMap::new();
            for ((name, name_span), f) in fs {
                if funcs.insert(name.clone(), f).is_some() {
                    emitter.emit(Rich::custom(
                        name_span.clone(),
                        format!("Function '{}' already exists", name),
                    ));
                }
            }
            funcs
        })
}

struct Error {
    span: Span,
    msg: String,
}

fn eval_expr<'src>(
    expr: &Spanned<Expr<'src>>,
    funcs: &HashMap<&'src str, Func<'src>>,
    stack: &mut Vec<(&'src str, Value<'src>)>,
) -> Result<Value<'src>, Error> {
    Ok(match &expr.0 {
        Expr::Error => unreachable!(), // Error expressions only get created by parser errors, so cannot exist in a valid AST
        Expr::Value(val) => val.clone(),
        Expr::List(items) => Value::List(
            items
                .iter()
                .map(|item| eval_expr(item, funcs, stack))
                .collect::<Result<_, _>>()?,
        ),
        Expr::Local(name) => stack
            .iter()
            .rev()
            .find(|(l, _)| l == name)
            .map(|(_, v)| v.clone())
            .or_else(|| Some(Value::Func(name.clone())).filter(|_| funcs.contains_key(name)))
            .ok_or_else(|| Error {
                span: expr.1.clone(),
                msg: format!("No such variable '{}' in scope", name),
            })?,
        Expr::Let(local, val, body) => {
            let val = eval_expr(val, funcs, stack)?;
            stack.push((local.clone(), val));
            let res = eval_expr(body, funcs, stack)?;
            stack.pop();
            res
        }
        Expr::Then(a, b) => {
            eval_expr(a, funcs, stack)?;
            eval_expr(b, funcs, stack)?
        }
        Expr::Binary(a, BinaryOp::Add, b) => Value::Num(
            eval_expr(a, funcs, stack)?.num(a.1.clone())?
                + eval_expr(b, funcs, stack)?.num(b.1.clone())?,
        ),
        Expr::Binary(a, BinaryOp::Sub, b) => Value::Num(
            eval_expr(a, funcs, stack)?.num(a.1.clone())?
                - eval_expr(b, funcs, stack)?.num(b.1.clone())?,
        ),
        Expr::Binary(a, BinaryOp::Mul, b) => Value::Num(
            eval_expr(a, funcs, stack)?.num(a.1.clone())?
                * eval_expr(b, funcs, stack)?.num(b.1.clone())?,
        ),
        Expr::Binary(a, BinaryOp::Div, b) => Value::Num(
            eval_expr(a, funcs, stack)?.num(a.1.clone())?
                / eval_expr(b, funcs, stack)?.num(b.1.clone())?,
        ),
        Expr::Binary(a, BinaryOp::Eq, b) => {
            Value::Bool(eval_expr(a, funcs, stack)? == eval_expr(b, funcs, stack)?)
        }
        Expr::Binary(a, BinaryOp::NotEq, b) => {
            Value::Bool(eval_expr(a, funcs, stack)? != eval_expr(b, funcs, stack)?)
        }
        Expr::Call(func, args) => {
            let f = eval_expr(func, funcs, stack)?;
            match f {
                Value::Func(name) => {
                    let f = &funcs[&name];
                    let mut stack = if f.args.len() != args.len() {
                        return Err(Error {
                            span: expr.1.clone(),
                            msg: format!("'{}' called with wrong number of arguments (expected {}, found {})", name, f.args.len(), args.len()),
                        });
                    } else {
                        f.args
                            .iter()
                            .zip(args.iter())
                            .map(|(name, arg)| Ok((name.clone(), eval_expr(arg, funcs, stack)?)))
                            .collect::<Result<_, _>>()?
                    };
                    eval_expr(&f.body, funcs, &mut stack)?
                }
                f => {
                    return Err(Error {
                        span: func.1.clone(),
                        msg: format!("'{:?}' is not callable", f),
                    })
                }
            }
        }
        Expr::If(cond, a, b) => {
            let c = eval_expr(cond, funcs, stack)?;
            match c {
                Value::Bool(true) => eval_expr(a, funcs, stack)?,
                Value::Bool(false) => eval_expr(b, funcs, stack)?,
                c => {
                    return Err(Error {
                        span: cond.1.clone(),
                        msg: format!("Conditions must be booleans, found '{:?}'", c),
                    })
                }
            }
        }
        Expr::Print(a) => {
            let val = eval_expr(a, funcs, stack)?;
            println!("{}", val);
            val
        }
    })
}

fn main() {
    let src = env::args().nth(1).expect("Expected file argument");

    // let src = fs::read_to_string(&filename).expect("Failed to read file");

    let (tokens, mut errs) = lexer().parse(src.as_str()).into_output_errors();

    println!("{:#?}\n\n{:#?}", tokens.unwrap(), errs);

    // let parse_errs = if let Some(tokens) = &tokens {
    //     let (ast, parse_errs) = funcs_parser()
    //         .map_with_span(|ast, span| (ast, span))
    //         .parse(tokens.as_slice().spanned((src.len()..src.len()).into()))
    //         .into_output_errors();

    //     if let Some((funcs, file_span)) = ast.filter(|_| errs.len() + parse_errs.len() == 0) {
    //         if let Some(main) = funcs.get("main") {
    //             if main.args.len() != 0 {
    //                 errs.push(Rich::custom(
    //                     main.span,
    //                     format!("The main function cannot have arguments"),
    //                 ))
    //             } else {
    //                 match eval_expr(&main.body, &funcs, &mut Vec::new()) {
    //                     Ok(val) => println!("Return value: {}", val),
    //                     Err(e) => errs.push(Rich::custom(e.span, e.msg)),
    //                 }
    //             }
    //         } else {
    //             errs.push(Rich::custom(
    //                 file_span,
    //                 format!("Programs need a main function but none was found"),
    //             ));
    //         }
    //     }

    //     parse_errs
    // } else {
    //     Vec::new()
    // };

    // errs.into_iter()
    //     .map(|e| e.map_token(|c| c.to_string()))
    //     .chain(
    //         parse_errs
    //             .into_iter()
    //             .map(|e| e.map_token(|tok| tok.to_string())),
    //     )
    //     .for_each(|e| {
    //         Report::build(ReportKind::Error, filename.clone(), e.span().start)
    //             .with_message(e.to_string())
    //             .with_label(
    //                 Label::new((filename.clone(), e.span().into_range()))
    //                     .with_message(e.reason().to_string())
    //                     .with_color(Color::Red),
    //             )
    //             .with_labels(e.contexts().map(|(label, span)| {
    //                 Label::new((filename.clone(), span.into_range()))
    //                     .with_message(format!("while parsing this {}", label))
    //                     .with_color(Color::Yellow)
    //             }))
    //             .finish()
    //             .print(sources([(filename.clone(), src.clone())]))
    //             .unwrap()
    //     });
}
